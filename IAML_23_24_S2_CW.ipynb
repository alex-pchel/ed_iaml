{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b7e173",
   "metadata": {
    "id": "49b7e173"
   },
   "source": [
    "**<p style='text-align: right;'>Ver. 2.5.1</p>**\n",
    "\n",
    "# Introductory Applied Machine Learning (IAML) Coursework - Semester 2, 2023-24\n",
    "\n",
    "### Author: Fengxiang He, Waylon Li, Hiroshi Shimodaira and Rohan Gorantla\n",
    "\n",
    "## Important Instructions\n",
    "\n",
    "#### It is important that you follow the instructions below carefully for things to work properly.\n",
    "\n",
    "You need to set up and activate your environment as you would do for your labs, see Learn section on Labs.  **You will need to use Noteable to create the files you will submit (the Jupyter (IPynthon) Notebook and the PDF)**.  Do **NOT** create the PDF in some other way, we will not be able to mark it.  If you want to develop your answers in your own environment, you should make sure you are using the same packages we are using, by running the cell which does imports below.\n",
    "\n",
    "Read the instructions in this notebook carefully, especially where asked to name variables with a specific name. Wherever you are required to produce code you should use code cells, otherwise you should use markdown cells to report results and explain answers. In most cases we indicate the nature of answer we are expecting (code/text), and also provide the required code/markdown cell. **If you are not familiar with markdown, here's a tutorial: [click here](https://www.markdowntutorial.com/).**\n",
    "\n",
    "- We will use the IAML Learn page for any announcements, updates, and FAQs on this assignment. Please ***visit the page frequently*** to find the latest information/changes.\n",
    "- Data files that you will be using are included in the coursework zip file that you have downloaded from the Learn assignment page for this coursework.\n",
    "- There is a helper file 'iaml24cw_helpers.py' in the zip file, which you should upload to your environment.\n",
    "- Some of the topics in this coursework are covered in week 7 and 8 of the course. Focus first on questions or topics that you have covered already, and come back to the other questions as the lectures progress.\n",
    "- Keep your answers brief and concise.\n",
    "- Make sure to show all your code/working.\n",
    "- All the figures you present should have axis labels, titles, and grid lines unless specified explicitly. If you think grid lines spoiling readability, you can adjust the line width and/or line style. Figures should not be too small to read.\n",
    "- Write readable code. While we do not expect you to follow PEP8 to the letter, the code should be adequately understandable, with plots/visualisations correctly labelled. Do use inline comments when doing something non-standard.\n",
    "- When asked to present numerical values, make sure to represent real numbers in the appropriate precision corresponding to your answer.\n",
    "- When you use libraries specified in this coursework, you should use the default parameters unless specified explicitly.\n",
    "- The criteria on which you will be judged include the quality of the textual answers and/or any plots asked for. For higher marks, when asked you need to give good and concise discussions based on experiments and theories using your own words.\n",
    "\n",
    "- You will see <html>\\\\pagebreak</html> at the start of each subquestion.  ***Do not remove these, if you do we will not be able to mark your coursework.***\n",
    "\n",
    "#### Good Scholarly Practice\n",
    "Please remember the University requirement regarding all assessed work for credit. Details about this can be found at:\n",
    "http://web.inf.ed.ac.uk/infweb/admin/policies/academic-misconduct\n",
    "\n",
    "Specifically, this assignment should be your own individual work. We will employ tools for detecting misconduct.\n",
    "\n",
    "Moreover, please note that Piazza is NOT a forum for discussing the solutions of the assignment. You may ask private questions. You can use the office hours to ask questions.\n",
    "\n",
    "### SUBMISSION Mechanics\n",
    "This assignment will account for 30% of your final mark. We ask you to submit answers to all questions.\n",
    "\n",
    "You will submit (1) a PDF of your Notebook and (2) the Notebook itself via Gradescope.  Your grade will be based on the PDF, we will only use the Notebook if we need to see details.  **You must use the following procedure to create the materials to submit**.\n",
    "\n",
    "1. Make sure your Notebook, the helper file, and the datasets are in Noteable and will run.  If you developed your answers in Noteable, this is already done.\n",
    "\n",
    "2. Select **Kernel->Restart & Run All** to create a clean copy of your submission, this will run the cells in order from top to bottom.  This may take a while (a few hours) to complete, ensure that all the output and plots have complete before you proceed.\n",
    "\n",
    "3. Select **File->Download as->PDF via LaTeX (.pdf)** and wait for the PDF to be created and downloaded.\n",
    "\n",
    "4. Select **File->Download as->Notebook (.ipynb)**\n",
    "\n",
    "5. You now should have in your download folder the pdf and the notebook.  Rename them sNNNNNNN.pdf and sNNNNNNN.ipynb, where sNNNNNNN is your matriculation number (student number).\n",
    "\n",
    "**Details on submission instructions will be announced and documented on Learn before the deadline**.\n",
    "\n",
    "The submission deadline for this assignment is **Monday 1st April 2024 at 4pm UK time (UTC)**.  Don't leave it to the last minute!\n",
    "\n",
    "\n",
    "#### IMPORTS\n",
    "Execute the cell below to import all packages you will be using for this assignment.  If you are not using Noteable, make sure the python and package version numbers reported match the python and package numbers, which can be checked by running the following cell. The Python version does not need to be the same, but it should be $3.9.p$, where $p \\ge 12$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11f0c16",
   "metadata": {
    "id": "d11f0c16",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "\n",
    "#from iaml23cw_helpers import *\n",
    "#print_versions();\n",
    "\n",
    "# You may add other libraries here or in your other cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3503f",
   "metadata": {
    "id": "10c3503f"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4508de8",
   "metadata": {
    "id": "a4508de8"
   },
   "source": [
    "# Question 1: Experiments with a stock price  data set\n",
    "\n",
    "#### 65 marks out of 110 for this coursework\n",
    "\n",
    "The stock price data set we use in this coursework is a stock price of a company for the period between 2000 and 2024, consisting of four historical prices ('Open', 'High', 'Low', 'Close', which denote the opening, highest, lowest, and closing prices on the trading day, respectively) and trading volume. For the convenience of the coursework, we have added some features to the data set. They are four [technical indicators](https://python.stockindicators.dev/indicators/) (RSI, SMA, MACD, ADX), 'Tomorrow', and 'Target'. 'Tomorrow' holds the closing price of next trading day, which we will use for price prediction, and 'Target' is a binary indicator (label), which takes 1 if 'Tomorrow' is higher than 'Close', 0 otherwise, which we will use for the prediction of movement direction.\n",
    "\n",
    "***Loading data***\n",
    "Make sure that you have the data set files \"dset_q1a.csv\", \"dset_q1a_extend\", and \"dset_q1b.csv\" in your environment. We will use the first file in the following sub questions except the last two subquestions 1.7 and 1.8. Run the following cell to load the first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a17c90f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a17c90f4",
    "outputId": "9f9f77a6-e264-4259-ec44-35f25cc403e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SMA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ADX</th>\n",
       "      <th>Tomorrow</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>58.68750</td>\n",
       "      <td>59.3125</td>\n",
       "      <td>56.00000</td>\n",
       "      <td>58.28125</td>\n",
       "      <td>53228400</td>\n",
       "      <td>54.215625</td>\n",
       "      <td>71.898153</td>\n",
       "      <td>3.292083</td>\n",
       "      <td>38.756214</td>\n",
       "      <td>56.31250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>56.78125</td>\n",
       "      <td>58.5625</td>\n",
       "      <td>56.12500</td>\n",
       "      <td>56.31250</td>\n",
       "      <td>54119000</td>\n",
       "      <td>54.645313</td>\n",
       "      <td>60.689975</td>\n",
       "      <td>2.986482</td>\n",
       "      <td>37.855621</td>\n",
       "      <td>56.90625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>55.56250</td>\n",
       "      <td>58.1875</td>\n",
       "      <td>54.68750</td>\n",
       "      <td>56.90625</td>\n",
       "      <td>64059600</td>\n",
       "      <td>55.165625</td>\n",
       "      <td>62.584360</td>\n",
       "      <td>2.760381</td>\n",
       "      <td>35.986452</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>56.09375</td>\n",
       "      <td>56.9375</td>\n",
       "      <td>54.18750</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>54976600</td>\n",
       "      <td>55.621875</td>\n",
       "      <td>53.645906</td>\n",
       "      <td>2.399714</td>\n",
       "      <td>33.922343</td>\n",
       "      <td>55.71875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>54.31250</td>\n",
       "      <td>56.1250</td>\n",
       "      <td>53.65625</td>\n",
       "      <td>55.71875</td>\n",
       "      <td>62013600</td>\n",
       "      <td>56.089062</td>\n",
       "      <td>56.186787</td>\n",
       "      <td>2.147129</td>\n",
       "      <td>31.661532</td>\n",
       "      <td>56.12500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open     High       Low     Close    Volume        SMA  \\\n",
       "Date                                                                     \n",
       "2000-01-03  58.68750  59.3125  56.00000  58.28125  53228400  54.215625   \n",
       "2000-01-04  56.78125  58.5625  56.12500  56.31250  54119000  54.645313   \n",
       "2000-01-05  55.56250  58.1875  54.68750  56.90625  64059600  55.165625   \n",
       "2000-01-06  56.09375  56.9375  54.18750  55.00000  54976600  55.621875   \n",
       "2000-01-07  54.31250  56.1250  53.65625  55.71875  62013600  56.089062   \n",
       "\n",
       "                  RSI      MACD        ADX  Tomorrow  Target  \n",
       "Date                                                          \n",
       "2000-01-03  71.898153  3.292083  38.756214  56.31250       0  \n",
       "2000-01-04  60.689975  2.986482  37.855621  56.90625       1  \n",
       "2000-01-05  62.584360  2.760381  35.986452  55.00000       0  \n",
       "2000-01-06  53.645906  2.399714  33.922343  55.71875       1  \n",
       "2000-01-07  56.186787  2.147129  31.661532  56.12500       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data set \"dset_q1a.csv\"\n",
    "df = pd.read_csv(\"dset_q1a.csv\", index_col='Date', parse_dates=True)\n",
    "df.index = pd.to_datetime(df.index, format='%d/%m/%Y')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2943069",
   "metadata": {
    "id": "a2943069"
   },
   "source": [
    "# ========== Question 1.1 --- [5 marks] ==========\n",
    "###  Describe the main properties of the data:\n",
    "1. [Code] Display the shape of the data\n",
    "2. [Code] Display the range of the dataframe index\n",
    "3. [Code] What data are presented and what types of data are they? Display the information using **pandas.DataFrame.info**.\n",
    "4. [Code] Display the highest price, the lowest price, and the mean of the closing price ('Close') for each year in the data. (Hint: the highest price for each year is obtained from the price 'High'.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8301fd5",
   "metadata": {
    "id": "d8301fd5"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0c27cb",
   "metadata": {
    "id": "da0c27cb"
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad8689c",
   "metadata": {
    "id": "7ad8689c"
   },
   "outputs": [],
   "source": [
    "#(2) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eedf6554",
   "metadata": {
    "id": "eedf6554"
   },
   "outputs": [],
   "source": [
    "#(3) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a3a7731",
   "metadata": {
    "id": "4a3a7731",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#(4) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46c2ad",
   "metadata": {
    "id": "6d46c2ad"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece7b325",
   "metadata": {
    "id": "ece7b325"
   },
   "source": [
    "# ========== Question 1.2 --- [8 marks] ==========\n",
    "Perform an *exploratory data analysis* on the dataset by studying the following:\n",
    "1. [Code and text] Plot the stock market closing price ('Close') and analyse the plot by identifying key trends and volatility patterns\n",
    "2. [Code] For the period from the beginning of year 2021 until the end of 2022, plot the volumes ('Volume'), where you show months on the x-axis and indicate the positions of the highest and lowest values for the period.\n",
    "3. [Code and text] Plot a pairplot for the dataset features using the seaborn **pairplot**. Examine and describe specific correlations and distributions among the features. Highlight any strong or weak correlations observed between pairs of features and discuss potential implications for further analysis.\n",
    "4. [Code] Plot the correlation matrix for the dataset features.\n",
    "5. [Text] Based on the results you obtained in 3 and 4 above, comment on the relationships among the features present in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dd28e2",
   "metadata": {
    "id": "a5dd28e2"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfff1bff",
   "metadata": {
    "id": "cfff1bff"
   },
   "outputs": [],
   "source": [
    "#(1) Your code and text goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f94216ee",
   "metadata": {
    "id": "f94216ee"
   },
   "outputs": [],
   "source": [
    "#(2) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10571c2b",
   "metadata": {
    "id": "10571c2b"
   },
   "outputs": [],
   "source": [
    "#(3) Your code and text goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7dc09b7",
   "metadata": {
    "id": "e7dc09b7"
   },
   "outputs": [],
   "source": [
    "#(4) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca341a",
   "metadata": {
    "id": "e3ca341a"
   },
   "source": [
    "#(5) Your text goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23cd97",
   "metadata": {
    "id": "ad23cd97"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1303cb",
   "metadata": {
    "id": "ce1303cb"
   },
   "source": [
    "# ========== Question 1.3 --- [9 marks] ==========\n",
    "\n",
    "We here apply linear regression to predict 'Tomorrow' from 'MACD'.\n",
    "For this question, you should use the sklearn implementation of Linear Regression. Use the first 80% of the data for training and the remaining 20% for testing ***without shuffling***.\n",
    "1. [Code] Fit a linear regression model to the training data so that we can predict 'Tomorrow' from 'MACD'. Report the estimated model parameters $w$ and the coefficient of determination $R^2$.\n",
    "2. [Text] Interpret the coefficient ($w$) for 'MACD' in the linear regression model. Discuss how changes in 'MACD' are expected to influence the prediction of 'Tomorrow'.\n",
    "3. [Code] Report the root mean-square error (RMSE) for the training set and test set, respectively.\n",
    "4. [Code] Plot predicted values versus actual values for the test set, where the x-axis corresponds to actual values and the y-axis to predicted values. Draw a line of $y=x$ on the plot.\n",
    "5. [Code] Plot 'Tomorrow' versus 'MACD' for the training set and display the regression line on the same graph. The x-axis corresponds to 'MACD' and the y-axis to 'Tomorrow'.\n",
    "6. [Text] Examining the results (e.g. $R^2$ and RMSE), discuss the model's reliability for financial forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a43b4f",
   "metadata": {
    "id": "93a43b4f"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a01c1d43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T17:30:24.162077Z",
     "start_time": "2024-02-29T17:30:24.141077Z"
    },
    "id": "a01c1d43"
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abdadee",
   "metadata": {
    "id": "5abdadee"
   },
   "source": [
    "#(2) Your text goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00188f50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T17:29:03.587977Z",
     "start_time": "2024-02-29T17:29:03.577453Z"
    },
    "id": "00188f50"
   },
   "outputs": [],
   "source": [
    "#(3) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58656607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T17:29:04.703929Z",
     "start_time": "2024-02-29T17:29:04.599896Z"
    },
    "id": "58656607"
   },
   "outputs": [],
   "source": [
    "#(4) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4d78bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T17:29:06.052669Z",
     "start_time": "2024-02-29T17:29:05.929653Z"
    },
    "id": "c4d78bd6"
   },
   "outputs": [],
   "source": [
    "#(5) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c2c91",
   "metadata": {
    "id": "710c2c91"
   },
   "source": [
    "#(6) Your text goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993ba49",
   "metadata": {
    "id": "1993ba49"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed87a29",
   "metadata": {
    "id": "3ed87a29"
   },
   "source": [
    "# ========== Question 1.4 --- [5 marks] ==========\n",
    "\n",
    "1. [Code] Instead of using `sklearn` for linear regression, implement an **analytical solution** for linear regression to predict the 'Tomorrow' variable using the 'MACD' feature. Explicitly calculate the regression coefficients without relying on external optimization libraries. Run your code and show the coefficients, using the same training data as Question 1.3.\n",
    "2. [Text] One of the common metric used for evaluating the performance of regression models is Mean Squared Error (MSE). Write out the expression for MSE and list one of its limitations and how it can be addressed with alternative metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da10dad6",
   "metadata": {
    "id": "da10dad6"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f203657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T17:31:00.817050Z",
     "start_time": "2024-02-29T17:31:00.804036Z"
    },
    "id": "3f203657"
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c4e5a0",
   "metadata": {
    "id": "c0c4e5a0"
   },
   "source": [
    "#(2) Your text goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5274d5f",
   "metadata": {
    "id": "b5274d5f"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5560a",
   "metadata": {
    "id": "3ea5560a"
   },
   "source": [
    "# ========== Question 1.5 --- [6 marks] ==========\n",
    "#### Multiple linear regression and polynomial regression\n",
    "\n",
    "We here consider multiple linear regression that employs four variables (RSI, SMA, MACD, ADX) to predict 'Tomorrow'. We use the same training data and test data as Question 1.3.\n",
    "1. [Code] Train the multiple linear regression model on the training set and show the model parameters and the coefficient of determination $R^2$. You also show the RMSE for the training set and test set respectively.\n",
    "2. [Code] We now extend the model to the polynomial regression model, in which we use all polynomial combinations of the variables up to the specified degree $p$. Using $p=2$, run an experiment in the same manner as 1 above and report the model parameters and $R^2$. You also report the RMSE for the training and test sets respectively. You should use the sklearn implementation of Linear Regression and Polynomial Features.\n",
    "3. [Text] Analyse and compare the performance of the multiple linear regression model and the polynomial regression model (with $p=2$) against the results from Question 1.3. Focus your discussion on the differences in $R^2$ and RMSE values across the models, and what these differences indicate about the models' ability to predict 'Tomorrow' from the given variables. Consider discussing model complexity, overfitting, and predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3175e",
   "metadata": {
    "id": "ecb3175e"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2261882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T17:31:41.590009Z",
     "start_time": "2024-02-29T17:31:41.571995Z"
    },
    "id": "e2261882"
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b2aac40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T17:31:46.039951Z",
     "start_time": "2024-02-29T17:31:46.022953Z"
    },
    "id": "3b2aac40"
   },
   "outputs": [],
   "source": [
    "#(2) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9150e",
   "metadata": {
    "id": "66f9150e"
   },
   "source": [
    "#(3) Your text goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de3ffe4",
   "metadata": {
    "id": "5de3ffe4"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44b755",
   "metadata": {
    "id": "9f44b755"
   },
   "source": [
    "# ========== Question 1.6 --- [12 marks] ==========\n",
    "#### Classification\n",
    "\n",
    "We now consider the prediction of stock price movement as a binary classification problem - class 1 for upward movement and class 0 otherwise. We use the four technical Indicators, 'RSI', 'SMA', 'MACD', 'ADX', as input features to a classifier to predict 'Target'.\n",
    "\n",
    "1. [Code] Using 15-fold cross validation with ***no shuffling*** on ***the whole data***, train four classifiers, Logistic Regression, SVM, Decision Trees, and Random Forests. Display, in a single graph, the validation accuracy with boxplot for each model. For each model, you also report the mean accuracy and mean F-score for the training set and validation set, respectively.\n",
    "(NB: You should obtain the accuracy and F-score for each trial of k-fold cross validation, which will be used for plotting a boxplot. A mean value/score denotes the average value over the $k$ trials, where $k=15$).\n",
    "<br> ***Note***: you should use sklearn's KFold, SVC, DecisionTreeClassifier, RandomForestClassifier, and LogisticRegression. Use `random_state=0` for all models.\n",
    "2. [Code] Further to the above, for each model, display the confusion matrix for the validation sets, where rows correspond to true class labels and columns to predicted ones, and each element of the matrix shows the number of corresponding instances.\n",
    "3. [Text] Comment on which model is best with respect to false positives and false negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7baf33",
   "metadata": {
    "id": "ae7baf33"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7868d3f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T17:33:35.654788Z",
     "start_time": "2024-02-29T17:32:42.171780Z"
    },
    "id": "7868d3f7"
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff7a44ca",
   "metadata": {
    "id": "ff7a44ca"
   },
   "outputs": [],
   "source": [
    "#(2) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839b579",
   "metadata": {
    "id": "e839b579"
   },
   "source": [
    "#(3) Your text goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad2ba5",
   "metadata": {
    "id": "82ad2ba5"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc12ea8",
   "metadata": {
    "id": "2fc12ea8"
   },
   "source": [
    "# ========== Question 1.7 --- [5 marks] ==========\n",
    "\n",
    "\n",
    "We considered only four technical features so far to find that movement classification with the four classifiers is challenging.\n",
    "This time we use another data set file (\"dset_q1a_extend.csv\"), which is an extended version of the original one and contains 16 technical indicators. Load the dataset in the following manner\n",
    ">   df1b = pd.read_csv(\"dset_q1a_extend.csv\", index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "However, we only use **5% of data for training** and the remaining 95% for testing.\n",
    "\n",
    "1. [Code] Split the data into two subsets with `random_state=0` with **no shuffling** - the first 5% of data should be used for training, and the remaining 95% for testing. Standardize the features using `StandardScaler` and train three logistic regression models with the following settings:\n",
    "    - Without regularization\n",
    "    - With L1 regularization and `liblinear` solver\n",
    "    - With L2 regularization and `liblinear` solver \n",
    "\n",
    "   Report the accuracy and F1 score for these three models as well as the weights of the three models.\n",
    "2. [Text] Discuss the implications of using L1 regularization versus L2 regularization in logistic regression models. Consider scenarios where one might be preferred over the other, and how the choice of regularization parameter ($\\lambda$ or `C` in scikit-learn) affects model complexity and feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd2d62",
   "metadata": {
    "id": "40fd2d62"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0617e9883f26710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T19:08:01.105787Z",
     "start_time": "2024-02-29T19:08:00.486671Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb419ba2e5c094ef",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#(2) Your text goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe5392",
   "metadata": {
    "id": "3dbe5392"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aed46d",
   "metadata": {
    "id": "29aed46d"
   },
   "source": [
    "# ========== Question 1.8 --- [15 marks] ==========\n",
    "\n",
    "This is a mini-project where the goal is to predict fraudulent transactions. You will focus on understanding and selecting appropriate evaluation metrics for imbalanced classification tasks. \n",
    "- You will be working on \"dset_q1b.csv\" with transaction features and a binary target variable `is_fraud` indicating fraud. All the features have been preprocessed to numerical values. Other necessary preprocessing steps might be needed such as feature scaling.\n",
    "- Import the packages you need and load the data set in the following manner: `df1b = pd.read_csv(\"dset_q1b.csv\")`\n",
    "- All the `random states` of `SMOTE`, `train_test_split`, `DecisionTreeClassifier`, etc. should be set to 0.\n",
    "\n",
    "\n",
    "1. [Code and Text] Shuffle and Split the data into two subsets with `random_state=0`. 80% of data should be used for training and validation, and the remaining 20% for testing. **Please also make sure the proportion of the positive class in the training and test set is the same as the original dataset.** Plot two pie charts to visualize the class distribution of the target variable for training and test set with labels and percentages in 3 decimal places.\n",
    "\n",
    "2. [Text] Before implementing the models, discuss the challenges of evaluating classifiers on imbalanced datasets. Specifically, address why traditional metrics such as accuracy may not be appropriate in the context of fraud detection. Propose alternative metrics that could provide a more meaningful assessment of classifier performance in detecting fraudulent transactions.\n",
    "\n",
    "3. [Code and Text] Apply feature scaling to the data. Subsequently, train three logistic regression models with `random_state=0`:\n",
    "    - Logistic regression without class weighting (`logit_none`)\n",
    "    - Logistic regression with a class weight of 1:7 (majority class : minority class) (`logit_custome`)\n",
    "    - Logistic regression with `class_weight` parameter set to `balanced` (`logit_balance`)\n",
    "    - Gaussian Naive Bayes\n",
    "    - KNN with `n_neighbors=5`, `n_jobs=-1` \n",
    "\n",
    "    After model training, plot the ROC curves in one graph for all three models. By only looking at the ROC curves, can you tell which model is the best? Why or why not?\n",
    "\n",
    "4. [Code and Text] In addition to the ROC curves, calculate the selected metrics from question 2 for the models in question 3 on the test set. The results should be shown in a numerical table and necessary figures. With the results obtained, give a quantitative comparison of the performance for the three logistic models. Discuss the strengths and weaknesses of each classifier in the context of fraud detection, and justify which classifier you would choose for the task. There is no standard answer to this question, but you should provide a clear and well-justified argument.\n",
    "\n",
    "5. [Code] Adjusting the threshold is a common technique to improve the performance of classifiers on imbalanced datasets. For the `logit_none` setting, identify a key metric that you would like to improve and find the optimal threshold that maximizes it before testing the model on the test set. Report the found threshold and the complete set of metrics from Question 2 on the test set with the new threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbadadba",
   "metadata": {
    "id": "bbadadba"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "584786ab",
   "metadata": {
    "id": "584786ab",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (1) Your code and text goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c80a8e980844c9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#(2) Your text goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ebdab9fa1cb7be1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#(3) Your code and text goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66e407526ef24d2f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#(4) Your code and text goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6197cd0ccab1585e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#(5) Your code and text goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22303f35",
   "metadata": {
    "id": "22303f35"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b684e",
   "metadata": {
    "id": "406b684e"
   },
   "source": [
    "# Question 2: Experiments with a census income dataset\n",
    "\n",
    "#### 45 marks out of 110 for this coursework\n",
    "\n",
    "The \"Adult\" dataset is a widely-used public dataset extracted by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0)).\n",
    "\n",
    "It is usually used for research in calssification task - determining whether a person makes over $50K p.a. from demographic information, including age, work class, education, gender, race, capital gain and loss, and hours worked per week. Also because of the nature of demographic information, this dataset is also popular in research of AI's algorithmic fairness.\n",
    "\n",
    "We have done a preparatory data cleansing, which removes all features involving missing values and other 11 features remain.\n",
    "\n",
    "**Link:** https://archive.ics.uci.edu/dataset/2/adult\n",
    "\n",
    "***Loading data:***\n",
    "Make sure that you have the data set files \"adult.data\" and \"adult.test\" in your environment and run the following cell to load the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d2aad91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "1d2aad91",
    "outputId": "374cb824-8138-4950-9395-d2850cc54868"
   },
   "outputs": [],
   "source": [
    "# Load the data set and apply some preprocessing\n",
    "\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race',\n",
    "           'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df_train = pd.read_csv(\"adult.data\", names=columns)\n",
    "df_train = df_train[['age', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'income']]\n",
    "df_test = pd.read_csv(\"adult.test\", names=columns).iloc[1:]\n",
    "df_test = df_test[['age', 'fnlwgt', 'education', 'education-num',\n",
    "                'marital-status', 'relationship', 'race', 'sex',\n",
    "                'capital-gain', 'capital-loss', 'income']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f51e03d",
   "metadata": {
    "id": "4f51e03d"
   },
   "source": [
    "# ========== Question 2.1 --- [5 marks] ==========\n",
    "\n",
    "Visualise the data:\n",
    "\n",
    "1. [Code] There are some features are not in the form of integer; use sklearn's **LableEncoder** to transform them into the form of integer.\n",
    "2. [Code] Use pandas's **parallel_coordinates** to visualise the features **'age'**, **'education-num'**, and **'race'** in the traning set **df_train**; the data points in different classes should be coloured differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6bf5c",
   "metadata": {
    "id": "ffd6bf5c"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "234500a8",
   "metadata": {
    "id": "234500a8"
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "JDYEfCp6WSoC",
   "metadata": {
    "id": "JDYEfCp6WSoC"
   },
   "outputs": [],
   "source": [
    "#(2) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377edd6c",
   "metadata": {
    "id": "377edd6c"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43937688",
   "metadata": {
    "id": "43937688"
   },
   "source": [
    "# ========== Question 2.2 --- [10 marks] ==========\n",
    "\n",
    "Apply K-means (with $k = 3$) to perform clustering on the Adult dataset.\n",
    "\n",
    "1. [Code] Apply sklearn's **KMeans** specifying **n_clusters=3** and **random_state=0** to the dataset, while all other parameters are set as default. Note that the two parameters should be set explicitly.\n",
    "2. [Code] Use matplotlib's **pyplot** to plot the cluster centres' **('age', 'fnlwgt'** features on a plane; data points from different classes should be in different colours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935fea86",
   "metadata": {
    "id": "935fea86"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4daeb599",
   "metadata": {
    "id": "4daeb599"
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8dcb3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a112e0",
   "metadata": {
    "id": "64a112e0"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007403e9",
   "metadata": {
    "id": "007403e9"
   },
   "source": [
    "# ========== Question 2.3 --- [5 marks] ==========\n",
    "\n",
    "Use Principal Component Analysis (PCA) to perform dimension reduction on the dataset.\n",
    "\n",
    "1. [Code] Use sklearn's **PCA** to perform PCA to the data **df**. Calcualte and show the **variances** of all the ten **principal components**.\n",
    "2. [Code] Plot the **cumulative explained variance ratio** $r_i$ as a function of the number of principal components, $i$ ($ 1 \\le i ≤ D$, $D$ is the data dimension). $r_i$ is defined as follows,\n",
    "> $$ r_i = \\frac{\\sum_{j=1}^i \\lambda_j}{\\sum_{j=1}^D \\lambda_j}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23bb13e",
   "metadata": {
    "id": "f23bb13e"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78270c35",
   "metadata": {
    "id": "78270c35"
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee5e1199",
   "metadata": {
    "id": "ee5e1199",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#(2) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c7f0a",
   "metadata": {
    "id": "c32c7f0a"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c8610",
   "metadata": {
    "id": "a63c8610"
   },
   "source": [
    "# ========== Question 2.4 --- [10 marks] ==========\n",
    "\n",
    "We now would like to know how the training data **df_train** distribute in a vector space. To visualise distributions, we reduce the dimensionality of the data to **2** using PCA, and then plot the dimensionality-reduced data on a two-dimensional \"plane\" spanned by the first two principal components. Note that each instance in the dataset is now displayed as a single point on the plane.\n",
    "\n",
    "1. [Code] Plot the training data **df_train** on the two-dimensional PCA plane, where the data points from different classes are coloured differently. Adjust the marker size to reduce the overlapping area.\n",
    "2. [Text] Discuss the separation of the classes. Explain your findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e89796e",
   "metadata": {
    "id": "3e89796e"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30f40646",
   "metadata": {
    "id": "30f40646"
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b277bc",
   "metadata": {
    "id": "03b277bc"
   },
   "source": [
    "#(2) ***Your text goes here***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246e180",
   "metadata": {
    "id": "2246e180"
   },
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e8290a",
   "metadata": {
    "id": "e5e8290a"
   },
   "source": [
    "# ========== Question 2.5 --- [15 marks] ==========\n",
    "\n",
    "We now apply classification to the dataset. Make sure that you use **df_train** for training and **df_test** for testing.\n",
    "1. [Code] Use sklearn's **LogisticRegression** (with **random_state=0**) to perform classification on the dataset. Calculate and report the classification accuracy and confusion matrix on both training set and test set. Use sklearn's **ConfusionMatrixDisplay** to display the confusion matrix. Note that you may ignore a warning message in the training.\n",
    "2. [Code] Use sklearn's **SVC** (with **random_state=0**) to perform SVM on the dataset. Calculate and report the classification accuracy and confusion matrix on both training set and test set.\n",
    "3. [Text] Based on the results obtained in 1 and 2, discuss your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88cb57a",
   "metadata": {
    "id": "e88cb57a"
   },
   "source": [
    "\\pagebreak\n",
    "## Your answers for Question 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "BknLsvoLrem6",
   "metadata": {
    "id": "BknLsvoLrem6"
   },
   "outputs": [],
   "source": [
    "#(1) Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3f42f4a",
   "metadata": {
    "id": "d3f42f4a"
   },
   "outputs": [],
   "source": [
    "#(2) Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d33422",
   "metadata": {
    "id": "a7d33422"
   },
   "source": [
    "#(3) Your text goes here"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
